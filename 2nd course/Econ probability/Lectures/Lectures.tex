\documentclass[a4paper, 10pt]{article}
\usepackage{header}

\title{\LARGE{Теория вероятности и математическая статистика—1}}
\author{Винер Даниил  \href{https://t.me/danya_vin}{@danya\_vin}}
\date{Версия от \today}
\begin{document}
\maketitle
\tableofcontents
\setlength{\parindent}{15pt}
\setlength{\parskip}{2mm}
\newpage
\section{Дискретное вероятностное пространство. Базовые теоремы вероятности}
\definition $\Omega=\{\omega_1,\ldots,\omega_k,\ldots\}$ называется \textit{пространством элементарных исходов}, где $w_i$ — элементарный исход\\[2mm]
\definition $A$ — любое подмножество $\Omega$\\[2mm]
\definition Событие называется \textit{достоверным}, если $A=\Omega$\\[2mm]
\comment К $A$ применимы те же опреации, что используются с множествами\\[2mm]
\definition Полная группа несовместных событий — такой набор событий, для которого выполняются такие условия:
\begin{equation*}
    A_i\cap A_j=\varnothing\ \forall i\ne j
\end{equation*}
\begin{equation*}
    \displaystyle\bigcup\limits_i A_i=\Omega
\end{equation*}

\axiom $\forall \omega_i\ \exists p_i\geqslant0,$ при этом $\displaystyle\sum_i p_i=1$\\[2mm]
\corollary $0\leqslant p_i\leqslant1$\\[2mm]
\definition $P(A)=\sum_{w_i\in A} P(w_i)$, где $P(w_i)=p_i$\\[2mm]
\indent $(\Omega, P)$ — вероятностное пространство в дискретном случае\\[2mm]
\textbf{Подходы к определению вероятностей}
\begin{enumerate}
    \item Априорный (предварительное знание)
    \item Частотный (предел ряда частот)
    \item Модельный (математическая модель)
\end{enumerate}
\subsection{Классическое определение вероятности}
\indent Имеет место, когда исходы равновероятны\\[2mm]
\definition
$$P(A)=\displaystyle\frac{|A|}{|\Omega|}$$

\definition $P(A)=\sum_{\omega_i\in A}p(\omega_i)$
\subsection{Теорема сложения}
\indent $P(A\cup B)=P(A)+P(B)-P(A\cap B)$\\[2mm]
\indent $P(A_1\cup\ldots\cup A_n)=\sum_{i=1}^{n} P(A_i)-\sum_{i<j} (A_i\cap A_j)+\ldots+(-1)^{n-1}P(A_1\cap\ldots\cap A_n)$
\subsection{Условная вероятность}
$P(A|B)=\displaystyle\frac{P(A\cap B)}{P(B)}\ \forall B: P(B)>0$
\subsection{Теорема умножения}
$P(A_1\cap\ldots\cap A_n)=P(A_1)\cdot P(A_2|A_1)\cdot P(A_3|A_1\cap A_2)\cdot\ldots\cdot P(A_n|A_1\cdot\ldots\cdot A_{n-1})$

\section{Независимые события. Апостериорная и условная вероятности}
Напомним классическое определение вероятности
$$P(A)=\sum_{\omega_i\in A}p(\omega_i)$$

\comment $P(\overline{A})=1-P(A),\ P(\Omega)=1$

\subsection{Задача об авариях}
Известно, что в $40\%$ аварий виноваты пьяные водители. Утверждается, что из этого следует, что в $60\%$ случаев виноваты трезвые водители

Пусть есть такие события: $A$ — водитель пьян, $B$ — водитель трезв, $C$ — авария случилась

Формально, задача выглядит так: $P(A|C)=0.4\Longrightarrow P(B|C)=0.6$

Пусть $P(B)=0.05$

$\displaystyle\frac{P(C|A)}{P(C|B)}=\frac{P(C\cap A)/P(A)}{P(C\cap B)}=\frac{P(A|C)P(C)}{P(B|C)P(C)}\cdot\frac{P(B)}{P(A)}=\frac{0.4}{0.6}\cdot\frac{0.95}{0.05}\approx 12.7$

\subsection{Независимость событий}
\definition (интуитивное) События  $A\text{ и }B$ \textbf{независимы}, если $P(A|B)=P(A)$

\definition События $A\text{ и }B$ называются попарно независимыми, если:
\begin{equation*}
    \begin{aligned}
        P(A\cap B)&=P(A)\cdot P(B)\\
        P(A|B)P(B)&=P(A)\cdot P(B)\text{ — вытекает интуитивное определение}
    \end{aligned}
\end{equation*}

\definition События $A_1,\ldots, A_n$ независимы в соовокупности, если:
\begin{equation*}
    \begin{aligned}
    \forall i_1<\ldots<i_k<\ldots<i_n\ \forall k=1,\ldots,n:\\ P(A_{i_1}\cap A_{i_2}\cap\ldots\cap A_{i_k})=P(A_{i_1})\cdot P(A_{i_2})\cdot \ldots\cdot P(A_{i_k})
    \end{aligned}
\end{equation*}

\comment  Для $A_1,A_2,A_3$:
\begin{equation*}
    \begin{aligned}
        P(A_1\cap A_2)&=P(A_1)\cdot P(A_2)\\
        P(A_2\cap A_3)&=P(A_2)\cdot P(A_3)\\
        P(A_1\cap A_3)&=P(A_1)\cdot P(A_3)\\
        P(A_1\cap A_2\cap A_3)&=P(A_1)\cdot P(A_2)\cdot P(A_3)
    \end{aligned}
\end{equation*}

\subsection{Пример зависимых событий в совокупности}
Положим, что у нас есть тетраэдр, каждая сторона которого покрашена в некоторые комбинации цветов: $A$ — красный, $B$ — желтый, $C$ — зеленый, а четвертая покрашена во все три цвета, тогда вероятности:
\begin{equation*}
    \frac{1}{4}=P(A\cap B\cap C)\ne P(A)\cdot P(B)\cdot P(C)=\frac{1}{8}
\end{equation*}
Таким образом, события зависимы в совокупности

\comment Если $A_1,\ldots, A_n$ независимы в совокупности, то над любым из событий можно поставить знак отрицания, тогда система останется независимой

\ex Есть события $A_1,A_2,A_3$ — независимы в совокупности, тогда $\overline{A_1},A_2,A_3$ — тоже независимы в совокупности

Проверим данный пример. 

\begin{equation*}
    \begin{aligned}
        P(\overline{A_1}\cap A_2\cap A_3)&=P((A_2\cap A_1)\setminus A_1)\\
        &=P(A_2)P(A_3)-P(A_1\cap A_2\cap A_3)\\
        &=P(A_2)P(A_3)-P(A_1)P(A_2)P(A_3)\\
        &=P(\overline{A_1})P(A_2)P(A_3)
    \end{aligned}
\end{equation*}
Теперь разберемся с двумя событиями
\begin{equation*}
    \begin{aligned}
        P(\overline{A_1}\cap A_2)&=P(\overline{A_1})P(A_2)\\
        P(\overline{A_2}\cap A_1)&=P(A_2\setminus A_1)\\
        &=P(A_2)-P(A_2\cap A_1)=P(A_2)-P(A_2)P(A_1)\\
        &=P(A_2)(1-P(A_1))
    \end{aligned}
\end{equation*}

\subsection{Простейший варинат ЗБЧ. Неизбежность технологических катастроф}
Имеется $n$ узлов, а $A_1,\ldots,A_n$ — события, где $A_i$ означает, что $i$-ый узел вышел из строя

Очевидно, что $P(\text{хотя бы один узел выйдет из строя})=P(A_1\cup \ldots \cup A_n)$, тогда $\forall i: 0<\varepsilon\leqslant P(A_i)<1$ выполняется:

% Вероятность стремится к 1 при увеличении количества узлов
$$1\geqslant P(A_1\cup \ldots \cup A_n)=1-P(\overline{A_1}\cap \ldots\cap\overline{A_n})=1-\displaystyle\prod_{i=1}^{n} \underbrace{P(\overline{A_i})}_{\leqslant 1-\varepsilon}\geqslant \lim\limits_{n\mapsto\infty}1-(1-\varepsilon)^n=1$$
% где каждое $P(\overline{A_i})=1-P(A_i)\leqslant 1-\varepsilon$

Это означает, что вероятность технологических катастроф при количестве узлов, стремящемся в бесконечность равна $100\%$
\subsection{Формула полной вероятности}
Пусть $\{H_i\}$ — полная группа несовместных событий (разбиение $\Omega$)

Некоторые свойства:
\begin{itemize}
    \item $H_i\cap H_j=\varnothing\ \forall i\ne j$ — несовместность\\[1mm]
    \item $\displaystyle\bigcup_{i=1}^{n}H_i=\Omega$ — полнота
\end{itemize}

\theorem Тогда, $P(A)=\sum_{i=1}^{n}P(A|H_i)P(H_i)$

\proof
\begin{equation*}
    \begin{aligned}
        P(A)&=P\left(\bigcup_{i=1}^{n}(A\cap H_i)\right)\\
        &=\sum_{i=1}^{n}P(A\cap H_i)\\
        &=\sum_{i=1}^{n} P(A|H_i)\cdot P(H_i)
    \end{aligned}
\end{equation*}\qed

\subsection{Формула Байеса. Апосториорные вероятности}
\begin{equation*}
    \begin{aligned}
        P(H_k|A)&=\frac{P(A|H_k)\cdot P(H_k)}{P(A)}\\
        &=\frac{P(A|H_k)\cdot P(H_k)}{\sum_{i=1}^{n} P(A|H_i)P(H_i)}
    \end{aligned}
\end{equation*}

\subsection{Задача про неизличимые заболевания}
Требуется вычислить, какова вероятность, что человек, который получил положительный тест на СПИД, на самом деле не болен

$P(\text{СПИД})=0.03$ — вероятность быть носителем СПИДа

$P(+|\text{ СПИД})=0.98$ — чувствительность теста, т.е. тест будет положительным, если у человека есть СПИД, с вероятностью $0.98$

$P(+|\overline{\text{СПИД}})=0.01=1-\text{специфичность}$, т.е. тест будет положительным, если у человека нет СПИДа, с вероятностью $0.01$

\begin{equation*}
    \begin{aligned}
        P(\text{СПИД}|+)&=\displaystyle\frac{P(+|\text{СПИД})P(\text{СПИД})}{P(+|\text{СПИД})P(\text{СПИД})+P(+|\overline{\text{СПИД}})P(\overline{\text{СПИД}})}\\
        &=\frac{0.98\cdot0.03}{0.98\cdot0.03+0.01\cdot0.97}\\
        &\approx0.75
    \end{aligned}
\end{equation*}
То есть, \textbf{каждый четвертый} человек с положительным СПИД-тестом \textbf{здоров}














\end{document}
